>Fault_Diagnosis_of_Ball_Bearing_Using_Dynamic_Convolutional_Neural_Networks_Under_Varying_Speed_Condition
 

베어링이 일정한 속도로 작동하면 정말 좋겠지만, 실제로는 부하 변동으로 인해 베어링에서는 크고 작은 속도 변동이 발생한다.

위 논문에서는 변속 조건 하에서의 결함 진단을 어떻게 할 것인가? 에 대한 질문을 던지게 된다. 

### 1. 왜 변속이 문제가 되는가?

---

가변 회전 속도 하의 진동 데이터 스펙트럼은, 회전 속도의 주파수 특징 뿐만 아니라 결함 주파수의 특징도 시간에 따라 변하기 때문에 스펙트림이 번지는(smearing) 현상이 발생한다.

따라서 가변 속도 조건에서의 스펙트럼을 통해 정확한 결함 주파수 특징을 얻고 볼 베어링의 결함을 진단하는 것은 매우매우매우 어렵다

![imageadga.png](imageadga.png)

 다양한 회전 상태에서 (a) 3초 길이, (b) 2초 길이, (c) 1초 길이의 볼 베어링 진동 데이터의 원시 신호 및 스펙트럼 속도조건

1초 및 2초 간격 데이터는 3초 간격 데이터의 중간 부분에 해당한다. 3초 동안 RPM이 765 증가할
때, 1초 동안 RPM이 245 증가하여, 짧은 구간 데이터가 상대적으로 일정한 회전 속도를 가졌음을 확인할 수 있었다

당연히 짧은 기간동안 속도는 크게 변하지 않을 것이다. (베어링이 빨라봐야 얼마나 빨라진다고…) 따라서 짧은 간격 데이터는 스펙트럼 번짐을 최소화하고, 이 결과를 바탕으로 변속 조건 하에서의 짧은 시간 간격으로 변속 데이터를 분할해서 진단하는 것이 좋다는 게 이 논문의 핵심이다. 

논문에서는 간격 길이를 1초로 설정했는데, 사실 1초 이하로 짧게 잡으면….

### 2. 동적 합성곱층

---

이 부분이 핵심인데, 논문은 어떠한 신경망을 제공해주진 않았다. (있긴 있는데 우리가 사용할 모델과는 다르다)

문제는 위 CNN을 만드는게 핵심이다. 1초라고 해도, 속도가 변하는게 문제라는 것이다. 문제는 1초동안 모든 데이터들이 일정하게 속도가 변했으면 좋겠는데, 무작위로 변하다 보니까 이게 참 어렵다는 것…

따라서 결함 유형과 회전 속도에 따라 결함 주파수가 달라지는 것을 착안하여 다음과 같은 합성곱층을 만들었다.

![image.png](image%201agfga.png)


1. 적응형 커널(K(x))을 사용한다. 
2. 가중치는 pi(x)인데, ReLU 활성화 함수와 소프트맥스를 적용한 두 개의 완젼 연결 층을 통해 생성한다. 입력은 전역 평균 풀링 (GAP)으로 처리한다. 
    1. 아니 입력을 GAP으로 설정해서 신경망의 맨 처음은 반드시 일반 합성곱을 써야 한다…..
    2. 가중치를 예측하는 신경망을 만들겠다는 것이다. 
    3. 참고로 가중치를 소프트맥스로 한번 더 눌러준다. 

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class DYCNN(nn.Module):
    def __init__(self, Cin, Cout, kernel_size = 4, num_basis_kernels = 4): 
        # 논문에서는 커널 사이즈와 커널 갯수를 4로 설정함 
        super(DYCNN, self).__init__()
        self.Cin = Cin # 입력 채널 수
        self.Cout = Cout # 출력 채널 수 
        self.kernel_size = kernel_size # 커널 사이즈 
        self.num_basis_kernels = num_basis_kernels 
        
        # 기본 커널 및 바이어스
        self.basis_kernels = nn.Parameter(torch.randn(num_basis_kernels, Cout, Cin, kernel_size, kernel_size)) # (num_basis_kernels, Cout, Cin, kernel_size, kernel_size)
        self.basis_biases = nn.Parameter(torch.randn(num_basis_kernels, Cout))
        
        # Attention weights를 계산하기 위한 완전 연결층
        self.fc1 = nn.Linear(Cin * kernel_size * kernel_size, 128)
        self.fc2 = nn.Linear(128, num_basis_kernels)
        
    def forward(self, x):
        batch_size, Cin, H, W = x.size() # 기본적으로 입력 데이터는 (N, C_in, H, W) 일 거라고 생각하기 
        
        # 입력을 전역 평균 풀링하여 1D 벡터로 변환
        pooled = F.adaptive_avg_pool2d(x, (1, 1))
        pooled = pooled.view(batch_size, -1) # (batch_size, )
        
        # Attention weights 계산 
        # 기존 CNN과 다른 점, 가중치를 출력해주는 새로운 신경망이 안쪽에 생성되어있다. 
        attn_weights = F.relu(self.fc1(pooled))
        attn_weights = F.softmax(self.fc2(attn_weights), dim=1)
        
        # 적응형 커널 및 바이어스 계산....??
        
```

아니 이거 말이 안되는데…. 형상이 안맞는다.

에초에 저 수식도 이상하다 

필터 형상 (num_basis_kernels, Cin, kernel_size, kernel_size) 이건데, 하필 필터를 위한 가중치는 (num_basis_kernels, N) 이다. 그니까 입력되는 이미지의 배치 숫자를 고려하지 않은 수식이다.

이 중요한 난재를 해결하기 위해서, 수 많은 고민 끝에 배치를 뭉개버리기로 했다. 이게 아니면 딱히 방법이 없다.

무엇보다 그냥 더하기(+)의 역전파는 계산그래프상 입력값 그대로 나가는거라 영향도 별로 없을테고…. 잘못 구현한 걸수도 있는데 내 머리로는 이게 한계다 ㅋㅋ...

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class DYCNN(nn.Module):
    def __init__(self, Cin, Cout, hidden_size = 128, kernel_size = 4, num_basis_kernels = 4): 
        # 논문에서는 커널 사이즈와 커널 갯수를 4로 설정함 
        super(DYCNN, self).__init__()
        self.Cin = Cin # 입력 채널 수
        self.Cout = Cout # 출력 채널 수 
        self.kernel_size = kernel_size # 커널 사이즈 
        self.num_basis_kernels = num_basis_kernels 
        
        # 기본 커널 및 바이어스
        self.basis_kernels = nn.Parameter(torch.randn(num_basis_kernels, Cin, kernel_size, kernel_size)) # 필터 형상 (num_basis_kernels, Cin, kernel_size, kernel_size)
        self.basis_biases = nn.Parameter(torch.randn(num_basis_kernels)) # 필터 편향 형상 (num_basis_kernels, 1) 브로드캐스트를 쓸거라 1로 하자 
        
        # Attention weights를 계산하기 위한 완전 연결층
        self.fc1 = nn.Linear(Cin, hidden_size)
        self.fc2 = nn.Linear(hidden_size, num_basis_kernels) # 커널 갯수만큼 곱해주기 위해서....
        
    def forward(self, x):
        batch_size, Cin, H, W = x.size() # 기본적으로 입력 데이터는 (N, C_in, H, W) 일 거라고 생각하기, 아니더라도 필요한건 배치 갯수
        
        # 입력을 전역 평균 풀링하여 1D 벡터로 변환
        pooled = F.adaptive_avg_pool2d(x, (1, 1)) # (N, C, 1, 1)
        pooled = pooled.view(batch_size, -1) # (N, C) 
        
        # Attention weights 계산 
        # 기존 CNN과 다른 점, 가중치를 출력해주는 새로운 신경망이 안쪽에 생성되어있다. 
        attn_weights = F.relu(self.fc1(pooled)) # (N, hidden_size)
        
        # 적응형 커널 및 바이어스 계산
        # 이 부분을 어떻게 할까...
        # 아니 형상이 다른데 어떻게 곱해 미친거 아니냐?
        # 필터 형상 (num_basis_kernels, Cin, kernel_size, kernel_size) 이건데, 하필 필터를 위한 가중치는 (num_basis_kernels, N)이라서....
        # 깊은 고민의 끝에 그냥 필터를 손보기로 했다......
        # 그냥 축 N끼리 다 더해서 하나로 만들고 소프트맥스를 지나게 하자....

        attn_weights = self.fc2(attn_weights).sum(0) # (N, hidden_size) -> (N, num_basis_kernels) ->(N. num_basis_kernels) -> (num_basis_kernels, )
        attn_weights = F.softmax(attn_weights, dim = 0) # (num_basis_kernels, )

        K = self.basis_kernels * attn_weights
        b = self.basis_biases * attn_weights

        # 동적 합성곱 연산 수행
        y = F.conv2d(x, K, bias=b, stride=1, padding=self.kernel_size // 2)
        
        return y
```

---

### 수정본

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class DYCNN(nn.Module):
    def __init__(self, Cin, Cout, hidden_size = 128, kernel_size = 4, num_basis_kernels = 4): 
        # 논문에서는 커널 사이즈와 커널 갯수를 4로 설정함 
        super(DYCNN, self).__init__()
        self.Cin = Cin # 입력 채널 수
        self.Cout = Cout # 출력 채널 수 
        self.kernel_size = kernel_size # 커널 사이즈 
        self.num_basis_kernels = num_basis_kernels 
        self.conv = nn.Conv2d(Cin, Cout, kernel_size)
        # 기본 커널 및 바이어스
        #self.basis_kernels = nn.Parameter(torch.randn(num_basis_kernels, Cin, kernel_size, kernel_size)) # 필터 형상 (num_basis_kernels, Cin, kernel_size, kernel_size)
        self.basis_biases = nn.Parameter(torch.randn(num_basis_kernels)) # 필터 편향 형상 (num_basis_kernels, 1) 브로드캐스트를 쓸거라 1로 하자 
        
        # Attention weights를 계산하기 위한 완전 연결층
        self.fc1 = nn.Linear(Cin, hidden_size)
        self.fc2 = nn.Linear(hidden_size, num_basis_kernels) # 커널 갯수만큼 곱해주기 위해서....
        
    def forward(self, x):
        batch_size, Cin, H, W = x.size() # 기본적으로 입력 데이터는 (N, C_in, H, W) 일 거라고 생각하기, 아니더라도 필요한건 배치 갯수
        
        # 입력을 전역 평균 풀링하여 1D 벡터로 변환
        pooled = F.adaptive_avg_pool2d(x, (1, 1)) # (N, C, 1, 1)
        pooled = pooled.view(batch_size, -1) # (N, C) 
        
        x = self.conv(x) # (N, num_basis_kernels, OH, OW)

        # Attention weights 계산 
        # 기존 CNN과 다른 점, 가중치를 출력해주는 새로운 신경망이 안쪽에 생성되어있다. 
        attn_weights = F.relu(self.fc1(pooled)) # (N, hidden_size)
        attn_weights = self.fc2(attn_weights)# (N, hidden_size) -> (N, num_basis_kernels) 
        attn_weights = F.softmax(attn_weights, dim = 0) # (N, num_basis_kernels) 

        for n in range(batch_size):
            for i in range(self.num_basis_kernels):
                x[n,i,:,:] = x[n,i,:,:] * attn_weights[n,i] + self.basis_biases[i] * attn_weights[n,i] # (N, num_basis_kernels, OH, OW)

        return x
```

사용법

```python
# 모델 초기화 및 사용 예시
Cin = 3  # 입력 채널 수
Cout = 64  # 출력 채널 수
kernel_size = 3  # 커널 크기
batch = 4
model = DYCNN(Cin, Cout, kernel_size)

# 더미 입력 생성 (배치 크기: 8, 채널: 3, 높이: 32, 너비: 32)
input_tensor = torch.randn(8, Cin, 32, 32)
output = model(input_tensor)
print(output.shape)  # 예상 출력: (8, Cout, 32, 32)
```

### 2. 논문의 하이퍼파라미터 환경 설정
---
1. 옵티마이저 - Adam
2. 활성화 함수 - ReLU
3. 16kHz 샘플링 속도, 폭 25ms의 해밍 창(Hamming window), 10ms 스텝으로 FFT 변환해서 (256, 100) 크기의 스펙트로그램으로 변환